{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ac891b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from u2net import *\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e89b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  ipypixano import Pixano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da277132",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = U2NETP(3,1)\n",
    "\n",
    "state_dict=torch.load(\"u2netp.pth\",map_location='cpu')\n",
    "net.load_state_dict(state_dict)\n",
    "if torch.cuda.is_available():    net.cuda()\n",
    "net=net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8befccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema_shape={'category': [{'name': 'car', 'color': '#3c6127', \n",
    "                               'properties': [\n",
    "                                            {\"name\": 'occluded',    \"type\": 'checkbox' , \"default\": False },\n",
    "                                            { \"name\": 'model type', \"type\": 'dropdown' , \"enum\": ['toyota', 'chery', 'ford'], \"default\": 'toyota' },\n",
    "                                            { \"name\": 'color',      \"type\": 'textfield', \"default\": 'gray' }]},\n",
    "              {'name': 'bicycle', 'color': '#89c2bc', 'properties': []},\n",
    "              {'name': 'person', 'color': '#971ad2', 'properties': []},\n",
    "              {'name': 'motorcycle', 'color': '#e7e8d1', 'properties': []},\n",
    "              {'name': 'airplane', 'color': '#df753a', 'properties': []},\n",
    "              {'name': 'bus', 'color': '#075c52', 'properties': []},\n",
    "              {'name': 'train', 'color': '#a0da30', 'properties': []},\n",
    "              {'name': 'truck', 'color': '#7b0915', 'properties': []},\n",
    "              {'name': 'boat', 'color': '#2567cd', 'properties': []},\n",
    "              {'name': 'traffic sign', 'color': '#928520', 'properties': []},\n",
    "              {'name': 'fire hydrant', 'color': '#459511', 'properties': []},\n",
    "              {'name': 'stop sign', 'color': '#80e278', 'properties': []}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f04c105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets.widgets import Output\n",
    "\n",
    "output_infos=Output()\n",
    "output_size=320\n",
    "norm=transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
    "\n",
    "def deep_update_shape(change):\n",
    "    \n",
    "    annotations=change['new']\n",
    "    with  output_infos:\n",
    "        print(\"deep udpate\")\n",
    "    w,h=image.size\n",
    "    annotation=annotations[-1]\n",
    "    \n",
    "    vertices=np.array(annotation[\"geometry\"][\"vertices\"])\n",
    "   \n",
    "    if  vertices.shape[0]>10*2 : return\n",
    "\n",
    "    vertices[0:vertices.shape[0]:2]*=w\n",
    "    vertices[1:vertices.shape[0]:2]*=h\n",
    "\n",
    "    if annotation[\"geometry\"][\"type\"]==\"polygon\" :\n",
    "        vertices=vertices.reshape((-1,1,2)).astype(np.int32)\n",
    "        bd_rect=cv2.boundingRect(vertices)\n",
    "        vertices=np.array([bd_rect[0],bd_rect[1],bd_rect[0]+bd_rect[2],bd_rect[1]+bd_rect[3]])\n",
    "        vertices=vertices.flatten()\n",
    "\n",
    "    image_in_pil=image.crop(map(int,vertices))\n",
    "    w_i,h_i=image_in_pil.size\n",
    "    #display(image_in_pil)\n",
    "\n",
    "    image_in=image_in_pil.resize((output_size,output_size),resample=Image.BICUBIC)\n",
    "    image_in=np.array(image_in).astype(np.float)    \n",
    "\n",
    "    image_in = torch.Tensor(image_in/255.0).permute(2,0,1).float()\n",
    "    image_in=norm(image_in)\n",
    "    image_in=image_in.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output,*_ =net(image_in)\n",
    "    \n",
    "\n",
    "    pred = output.detach().numpy() #[:,0,:,:]\n",
    "    pred=(pred-pred.min())/(pred.max()-pred.min())\n",
    "    del output,_\n",
    "    \n",
    "    pred=(pred*255).astype(np.uint8).squeeze(0)\n",
    "    pred=Image.fromarray(pred).resize((w_i,h_i),resample=Image.BILINEAR)\n",
    "\n",
    "    bin_mask=(np.array(pred)>100).astype(np.uint8)\n",
    "    contours,_ = cv2.findContours(bin_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours)>0:\n",
    "        areas=[cv2.contourArea(cnt) for cnt in contours]\n",
    "        ind_max=np.argmax(areas)\n",
    "\n",
    "        cnt=cv2.approxPolyDP(contours[ind_max], 1, closed=True)\n",
    "        cnt=cnt.squeeze().flatten().astype(float)\n",
    "        cnt[0:cnt.shape[0]:2]=(cnt[0:cnt.shape[0]:2]+int(vertices[0]))/w\n",
    "        cnt[1:cnt.shape[0]:2]=(cnt[1:cnt.shape[0]:2]+int(vertices[1]))/h\n",
    "        annotations[-1][\"geometry\"]= {\"vertices\": list(cnt), \"type\": \"polygon\"} \n",
    "\n",
    "        #display(pred)\n",
    "        #image_out=(np.array(image_in_pil)*(np.array(pred)[:,:,None]).astype(np.float32)/255).astype(np.uint8)\n",
    "        #display(Image.fromarray(image_out))\n",
    "    #with output_infos:\n",
    "    #    print(annotations)\n",
    "    w_pix.setAnnotations(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e95d6e7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acd569f34184720b92d6585db1cadd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pixano(value=None, element='pxn-polygon', image='iVBORw0KGgoAAAANSUhEUgAACiAAAAeYCAIAAAAtiRqxAAAp9mVYSWZJSSoAC…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc8c978ec024ba4820ec192833f95f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'stream', 'text': 'deep udpate\\ndeep udpate\\ndeep udpate\\ndeep udpate\\ndeep ud…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8521/2888249225.py:33: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  image_in=np.array(image_in).astype(np.float)\n",
      "/tmp/ipykernel_8521/2888249225.py:33: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  image_in=np.array(image_in).astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "image=Image.open('/media/nallezard/My Passport1/Sofia_dataset/data/images/OA 435_NDOC177003_Corrosion foisonnante sur le m.jpg')\n",
    "#image=Image.open('image.jpg')\n",
    "w_pix = Pixano(element='pxn-polygon',image=image,label_schema=my_schema_shape)\n",
    "\n",
    "\n",
    "display(w_pix)\n",
    "display(output_infos)\n",
    "\n",
    "w_pix.observe(deep_update_shape, names='annotations')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481f42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "ipyemail",
   "language": "python",
   "name": "ipyemail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
